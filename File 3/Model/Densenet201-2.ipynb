{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc88bb82-7d20-4ce0-b29f-3ab6186b7cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import os\n",
    "import keras \n",
    "import random \n",
    "import cv2\n",
    "import math\n",
    "import seaborn as sns \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split \n",
    "import matplotlib.pyplot as plt #데이터 시각화용\n",
    "from tensorflow.keras.layers import Dense,GlobalAveragePooling2D,Convolution2D,BatchNormalization \n",
    "from tensorflow.keras.layers import Flatten,MaxPooling2D,Dropout\n",
    "from tensorflow.keras.applications import DenseNet201\n",
    "from tensorflow.keras.applications.densenet import preprocess_input \n",
    "from tensorflow.keras.preprocessing import image \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,img_to_array \n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam \n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614d5d9c-7fa2-4471-962f-c63a83a16f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2,3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48df7237-4395-4f08-8082-bde70bb4d266",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "labels=[]\n",
    "random.seed(42)\n",
    "imagePaths = sorted(list(os.listdir(\"emotion_fixed/\")))\n",
    "random.shuffle(imagePaths)\n",
    "print(imagePaths)\n",
    "\n",
    "for img in imagePaths:\n",
    "    path=sorted(list(os.listdir(\"emotion_fixed/\"+img)))\n",
    "    for i in path:\n",
    "        image = cv2.imread(\"emotion_fixed/\"+img+'/'+i)\n",
    "        image = cv2.resize(image, (48,48))\n",
    "        image = img_to_array(image)\n",
    "        data.append(image)\n",
    "        l = label = img\n",
    "        labels.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebcf485-1386-4e06-9cd0-7918c3de6e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data, dtype=\"float32\") / 255.0\n",
    "labels = np.array(labels)\n",
    "mlb = LabelBinarizer()\n",
    "labels = mlb.fit_transform(labels)\n",
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadfbe7e-5d96-422c-b474-2c983fb469fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "(xtrain,xtest,ytrain,ytest)=train_test_split(data,labels,test_size=0.3,random_state=42)\n",
    "print(xtrain.shape, xtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23277123-5f27-443c-a1ba-f4389148379a",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(zoom_range = 0.2, horizontal_flip=True, shear_range=0.2)\n",
    "datagen.fit(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13199436-68b2-4622-8efe-078e3491381e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain[0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc04051-9cca-4e67-88f0-e576fe18fb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_d=DenseNet201(weights='imagenet',include_top=False, input_shape=(48, 48, 3)) \n",
    "\n",
    "x=model_d.output\n",
    "\n",
    "x= GlobalAveragePooling2D()(x) \n",
    "x= BatchNormalization()(x) \n",
    "x= Dropout(0.5)(x)\n",
    "x= Dense(1024,activation='relu')(x) \n",
    "x= Dense(512,activation='relu')(x) \n",
    "x= BatchNormalization()(x)\n",
    "x= Dropout(0.5)(x)\n",
    "\n",
    "output=Dense(6,activation='softmax')(x)\n",
    "model=Model(model_d.input,output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0a3089-58b8-4c0b-a009-2b7c06fd3db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = Adam(lr=0.1), \n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    "  )\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99b9375-2b3a-48dd-9f1b-05bf8d7962f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(datagen.flow(xtrain, ytrain, batch_size=32),\n",
    "               epochs=100,\n",
    "               validation_data=(xtest, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f1e16a-a6c0-4748-b0b2-e9cf89d401bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(xtest, ytest, batch_size = 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097527e8-f2c0-43b0-87b5-b58ce4e6f919",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Densenet201_keras_emotion6ver_imsize48__lr0.001_epoch100.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b5db63-2253-4cd5-b486-e37d4c7ee6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#완성도 확인\n",
    "ypred = model.predict(xtest)\n",
    "\n",
    "total = 0\n",
    "accurate = 0\n",
    "accurateindex = []\n",
    "wrongindex = []\n",
    "\n",
    "for i in range(len(ypred)):\n",
    "    if np.argmax(ypred[i]) == np.argmax(ytest[i]):\n",
    "        accurate += 1\n",
    "        accurateindex.append(i)\n",
    "    else:\n",
    "        wrongindex.append(i)\n",
    "        \n",
    "    total += 1\n",
    "    \n",
    "print('Total-test-data;', total, '\\taccurately-predicted-data:', accurate, '\\t wrongly-predicted-data: ', total - accurate)\n",
    "print('Accuracy:', round(accurate/total*100, 3), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c4b681-3eb1-4531-ad93-627becff9823",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"model accuracy\")\n",
    "#plt.figure(10,20)\n",
    "plt.plot(history.history[\"accuracy\"])\n",
    "plt.plot(history.history[\"val_accuracy\"])\n",
    "plt.axis([1, 100, 0, 1])\n",
    "plt.ylabel(\"accuracy\", fontsize=15)\n",
    "plt.xticks(fontsize=13)\n",
    "plt.yticks(fontsize=13)\n",
    "plt.xlabel(\"epoch\", fontsize=15)\n",
    "plt.legend([\"train\", \"validation\"], loc=\"lower right\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4981638-2f4b-4c68-84d8-1ec8cbd9861d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from keras.models import model_from_json\n",
    "import numpy as np\n",
    "# from keras_preprocessing.image import load_img\n",
    "json_file = open(\"facialemotionmodel.json\", \"r\")\n",
    "model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(model_json)\n",
    "\n",
    "model.load_weights(\"facialemotionmodel.h5\")\n",
    "haar_file=cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'\n",
    "face_cascade=cv2.CascadeClassifier(haar_file)\n",
    "\n",
    "def extract_features(image):\n",
    "    feature = np.array(image)\n",
    "    feature = feature.reshape(1,48,48,1)\n",
    "    return feature/255.0\n",
    "\n",
    "webcam=cv2.VideoCapture(0)\n",
    "labels = {0 : 'angry', 1 : 'disgust', 2 : 'fear', 3 : 'happy', 4 : 'neutral', 5 : 'sad', 6 : 'surprise'}\n",
    "while True:\n",
    "    i,im=webcam.read()\n",
    "    gray=cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n",
    "    faces=face_cascade.detectMultiScale(im,1.3,5)\n",
    "    try: \n",
    "        for (p,q,r,s) in faces:\n",
    "            image = gray[q:q+s,p:p+r]\n",
    "            cv2.rectangle(im,(p,q),(p+r,q+s),(255,0,0),2)\n",
    "            image = cv2.resize(image,(48,48))\n",
    "            img = extract_features(image)\n",
    "            pred = model.predict(img)\n",
    "            prediction_label = labels[pred.argmax()]\n",
    "            # print(\"Predicted Output:\", prediction_label)\n",
    "            # cv2.putText(im,prediction_label)\n",
    "            cv2.putText(im, '% s' %(prediction_label), (p-10, q-10),cv2.FONT_HERSHEY_COMPLEX_SMALL,2, (0,0,255))\n",
    "        cv2.imshow(\"Output\",im)\n",
    "        cv2.waitKey(27)\n",
    "    except cv2.error:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3026b00-ea70-4cb5-972d-1c88c3ff4e5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
